{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np                                      \n",
    "\n",
    "import torch \n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import os\n",
    "from scipy.ndimage import gaussian_filter\n",
    "\n",
    "from sklearn.isotonic import IsotonicRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lead_time = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_path = f\"/work/scratch-nopw2/mendrika/OB/evaluation/predictions/ncast-nflics/val/t{lead_time}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = \"/work/scratch-nopw2/mendrika/OB/evaluation/calibration/ncast-nflics\"\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "out_path = os.path.join(out_dir, f\"isotonic_t{lead_time}.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.ndimage as nd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_cores(mask):\n",
    "    labelled, n = nd.label(mask > 0.5)\n",
    "    return n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max number of pixels to use for fitting\n",
    "max_samples = 1000\n",
    "\n",
    "# optional minimum probability to keep (to avoid the huge spike at pâ‰ˆ0 if you want)\n",
    "min_prob = 0.0\n",
    "\n",
    "all_p = []\n",
    "all_y = []\n",
    "\n",
    "for root, _, files in os.walk(val_path):\n",
    "    for fname in files:\n",
    "        if not fname.endswith(\".pt\"):\n",
    "            continue\n",
    "        fpath = os.path.join(root, fname)\n",
    "        data = torch.load(fpath, map_location=\"cpu\", weights_only=False)\n",
    "\n",
    "        mean = data[\"mean\"].detach().cpu().numpy().astype(np.float32)\n",
    "        gt = data[\"gt\"].detach().cpu().numpy().astype(np.uint8)\n",
    "\n",
    "\n",
    "        ncores = count_cores(gt)\n",
    "        if ncores < 15:\n",
    "            continue\n",
    "\n",
    "        p_flat = mean.ravel()\n",
    "        y_flat = gt.ravel()\n",
    "\n",
    "        if min_prob > 0.0:\n",
    "            mask = p_flat >= min_prob\n",
    "            p_flat = p_flat[mask]\n",
    "            y_flat = y_flat[mask]\n",
    "\n",
    "        all_p.append(p_flat)\n",
    "        all_y.append(y_flat)\n",
    "\n",
    "# concatenate all pixels\n",
    "p = np.concatenate(all_p)\n",
    "y = np.concatenate(all_y)\n",
    "\n",
    "n = p.shape[0]\n",
    "print(f\"Total pixels before subsampling: {n}\")\n",
    "\n",
    "if n > max_samples:\n",
    "    rng = np.random.default_rng(0)\n",
    "    idx = rng.choice(n, size=max_samples, replace=False)\n",
    "    p = p[idx]\n",
    "    y = y[idx]\n",
    "    print(f\"Subsampled to {max_samples} pixels for fitting\")\n",
    "\n",
    "print(\"Fitting isotonic regression...\")\n",
    "iso = IsotonicRegression(out_of_bounds=\"clip\")\n",
    "iso.fit(p, y)\n",
    "\n",
    "print(f\"Saving calibrator to {out_path}\")\n",
    "dump(iso, out_path)\n",
    "\n",
    "print(\"Done\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
